{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MTLSUgvVchb3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "A49JvZGfK9g0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for the training and test sets\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the training and test sets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YSVV7lngy4K3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the input tensor\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n"
      ],
      "metadata": {
        "id": "vJ-kl4QrzDW_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "oEHkglfYzZe5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "7RNCk0tqEhfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffe080d-b769-4de9-f00b-7d7b6eaf78cf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 0.4324\n",
            "Epoch [1/10], Step [200/938], Loss: 0.2779\n",
            "Epoch [1/10], Step [300/938], Loss: 0.1745\n",
            "Epoch [1/10], Step [400/938], Loss: 0.3732\n",
            "Epoch [1/10], Step [500/938], Loss: 0.1378\n",
            "Epoch [1/10], Step [600/938], Loss: 0.1605\n",
            "Epoch [1/10], Step [700/938], Loss: 0.0519\n",
            "Epoch [1/10], Step [800/938], Loss: 0.0654\n",
            "Epoch [1/10], Step [900/938], Loss: 0.1549\n",
            "Epoch [2/10], Step [100/938], Loss: 0.0188\n",
            "Epoch [2/10], Step [200/938], Loss: 0.2365\n",
            "Epoch [2/10], Step [300/938], Loss: 0.2074\n",
            "Epoch [2/10], Step [400/938], Loss: 0.1378\n",
            "Epoch [2/10], Step [500/938], Loss: 0.0787\n",
            "Epoch [2/10], Step [600/938], Loss: 0.1287\n",
            "Epoch [2/10], Step [700/938], Loss: 0.1627\n",
            "Epoch [2/10], Step [800/938], Loss: 0.1103\n",
            "Epoch [2/10], Step [900/938], Loss: 0.0332\n",
            "Epoch [3/10], Step [100/938], Loss: 0.1013\n",
            "Epoch [3/10], Step [200/938], Loss: 0.2451\n",
            "Epoch [3/10], Step [300/938], Loss: 0.1702\n",
            "Epoch [3/10], Step [400/938], Loss: 0.0564\n",
            "Epoch [3/10], Step [500/938], Loss: 0.0173\n",
            "Epoch [3/10], Step [600/938], Loss: 0.1185\n",
            "Epoch [3/10], Step [700/938], Loss: 0.0497\n",
            "Epoch [3/10], Step [800/938], Loss: 0.1140\n",
            "Epoch [3/10], Step [900/938], Loss: 0.0877\n",
            "Epoch [4/10], Step [100/938], Loss: 0.0301\n",
            "Epoch [4/10], Step [200/938], Loss: 0.0219\n",
            "Epoch [4/10], Step [300/938], Loss: 0.0899\n",
            "Epoch [4/10], Step [400/938], Loss: 0.0430\n",
            "Epoch [4/10], Step [500/938], Loss: 0.0570\n",
            "Epoch [4/10], Step [600/938], Loss: 0.0689\n",
            "Epoch [4/10], Step [700/938], Loss: 0.0468\n",
            "Epoch [4/10], Step [800/938], Loss: 0.1556\n",
            "Epoch [4/10], Step [900/938], Loss: 0.2259\n",
            "Epoch [5/10], Step [100/938], Loss: 0.0333\n",
            "Epoch [5/10], Step [200/938], Loss: 0.0400\n",
            "Epoch [5/10], Step [300/938], Loss: 0.0720\n",
            "Epoch [5/10], Step [400/938], Loss: 0.0721\n",
            "Epoch [5/10], Step [500/938], Loss: 0.1190\n",
            "Epoch [5/10], Step [600/938], Loss: 0.0520\n",
            "Epoch [5/10], Step [700/938], Loss: 0.1079\n",
            "Epoch [5/10], Step [800/938], Loss: 0.0072\n",
            "Epoch [5/10], Step [900/938], Loss: 0.0529\n",
            "Epoch [6/10], Step [100/938], Loss: 0.0278\n",
            "Epoch [6/10], Step [200/938], Loss: 0.0268\n",
            "Epoch [6/10], Step [300/938], Loss: 0.0037\n",
            "Epoch [6/10], Step [400/938], Loss: 0.0069\n",
            "Epoch [6/10], Step [500/938], Loss: 0.0694\n",
            "Epoch [6/10], Step [600/938], Loss: 0.0162\n",
            "Epoch [6/10], Step [700/938], Loss: 0.2042\n",
            "Epoch [6/10], Step [800/938], Loss: 0.0583\n",
            "Epoch [6/10], Step [900/938], Loss: 0.0597\n",
            "Epoch [7/10], Step [100/938], Loss: 0.0568\n",
            "Epoch [7/10], Step [200/938], Loss: 0.0214\n",
            "Epoch [7/10], Step [300/938], Loss: 0.0451\n",
            "Epoch [7/10], Step [400/938], Loss: 0.0650\n",
            "Epoch [7/10], Step [500/938], Loss: 0.1262\n",
            "Epoch [7/10], Step [600/938], Loss: 0.0297\n",
            "Epoch [7/10], Step [700/938], Loss: 0.2784\n",
            "Epoch [7/10], Step [800/938], Loss: 0.1150\n",
            "Epoch [7/10], Step [900/938], Loss: 0.0616\n",
            "Epoch [8/10], Step [100/938], Loss: 0.1569\n",
            "Epoch [8/10], Step [200/938], Loss: 0.0280\n",
            "Epoch [8/10], Step [300/938], Loss: 0.1508\n",
            "Epoch [8/10], Step [400/938], Loss: 0.0498\n",
            "Epoch [8/10], Step [500/938], Loss: 0.0062\n",
            "Epoch [8/10], Step [600/938], Loss: 0.0985\n",
            "Epoch [8/10], Step [700/938], Loss: 0.0136\n",
            "Epoch [8/10], Step [800/938], Loss: 0.1082\n",
            "Epoch [8/10], Step [900/938], Loss: 0.0105\n",
            "Epoch [9/10], Step [100/938], Loss: 0.0636\n",
            "Epoch [9/10], Step [200/938], Loss: 0.1002\n",
            "Epoch [9/10], Step [300/938], Loss: 0.0073\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0068\n",
            "Epoch [9/10], Step [500/938], Loss: 0.0019\n",
            "Epoch [9/10], Step [600/938], Loss: 0.0952\n",
            "Epoch [9/10], Step [700/938], Loss: 0.0419\n",
            "Epoch [9/10], Step [800/938], Loss: 0.1478\n",
            "Epoch [9/10], Step [900/938], Loss: 0.0293\n",
            "Epoch [10/10], Step [100/938], Loss: 0.0355\n",
            "Epoch [10/10], Step [200/938], Loss: 0.0069\n",
            "Epoch [10/10], Step [300/938], Loss: 0.0697\n",
            "Epoch [10/10], Step [400/938], Loss: 0.1980\n",
            "Epoch [10/10], Step [500/938], Loss: 0.0027\n",
            "Epoch [10/10], Step [600/938], Loss: 0.0102\n",
            "Epoch [10/10], Step [700/938], Loss: 0.1465\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0089\n",
            "Epoch [10/10], Step [900/938], Loss: 0.0344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the 10000 test images: {100 * correct / total}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUCccncOFLI9",
        "outputId": "8145feaf-a82c-43a5-86ef-61ff0202d216"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 97.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iu4CS-XYEjtk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pnz5MVpnElvw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXZFe85AEoPV"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}